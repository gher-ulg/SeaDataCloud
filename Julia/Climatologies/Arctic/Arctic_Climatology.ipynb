{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arctic regionional climatology for T and S\n",
    "Notebook for the creation of a climatology using a backgroud field.     \n",
    "Try to use Julia-1.3 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DIVAnd\n",
    "using PyPlot\n",
    "using NCDatasets\n",
    "using PhysOcean\n",
    "using DataStructures\n",
    "using PyPlot\n",
    "using Dates\n",
    "using Statistics\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and directories\n",
    "We assume that the data files are located in the `data` directory.     \n",
    "You can either modify the variable `datadir` or copy the data files into `./data/`.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = \"./data/\"\n",
    "figdir = \"./figures\"\n",
    "datafile = joinpath(datadir, \"data_from_SDN_2015-09_TS_ArcticOcean_QC_done_v2.nc\")\n",
    "datafileobs = \"./data/data_from_SDN_2015-09_TS_ArcticOcean_QC_done_v2_obs.nc\"\n",
    "varname = \"salinity\"\n",
    "isfile(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the files are large, it is wishable to read them and then convert them to a more suitable format using the function `saveos`, for example:\n",
    "```julia\n",
    "DIVAnd.saveobs(filename, varname, value, xy, ids,\n",
    "               type_save = Float32,\n",
    "               timeorigin = DateTime(1900,1,1,0,0,0),\n",
    "               used = trues(size(ids)),\n",
    "               )\n",
    "```\n",
    "Doing so, the reading of the data file(s) will be much faster, using:\n",
    "```julia\n",
    "obsvalue, obslon, obslat, obsdepth, obstime, obsid = loadobs(T, filename, varname)\n",
    "```\n",
    "Comment out the next cell if you have to change the format of the netCDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@time obsval, obslon, obslat, obsdepth, obstime, obsid = NCODV.load(Float64, datafile, \\\"Water body salinity\\\");\\ndatafile2 = joinpath(datadir, \\\"data_from_SDN_2015-09_TS_ArcticOcean_QC_done_v2_obs.nc\\\")\\n\\n@time DIVAnd.saveobs(datafile2, varname, obsval, (obslon, obslat, obsdepth, obstime), obsid,\\n               type_save = Float64,\\n               timeorigin = DateTime(1900,1,1,0,0,0),\\n               used = trues(size(obsid)),\\n               );\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@time obsval, obslon, obslat, obsdepth, obstime, obsid = NCODV.load(Float64, datafile, \"Water body salinity\");\n",
    "datafile2 = joinpath(datadir, \"data_from_SDN_2015-09_TS_ArcticOcean_QC_done_v2_obs.nc\")\n",
    "\n",
    "@time DIVAnd.saveobs(datafile2, varname, obsval, (obslon, obslat, obsdepth, obstime), obsid,\n",
    "               type_save = Float64,\n",
    "               timeorigin = DateTime(1900,1,1,0,0,0),\n",
    "               used = trues(size(obsid)),\n",
    "               );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "### Grid and depth levels\n",
    "For the tests, we only compute the climatology on a few depth levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Δx = 0.4\n",
    "Δy = 0.1\n",
    "lonr = 0.:Δx:80.\n",
    "latr = 67.0:Δy:80.0\n",
    "timerange = [Date(1890,1),Date(2020,12,31)];\n",
    "\"\"\"\n",
    "depthr = Float64.([0, 5, 10, 15, 20, 25, 30, 35, 40,\n",
    "        45, 50, 55, 60, 65, 70, 75, 80, 85, 90,\n",
    "        95, 100, 125, 150, 175, 200, 225, 250, 275, 300,\n",
    "        325, 350, 375, 400, 425, 450, 475, 500]);\n",
    "\"\"\"\n",
    "depthr = Float64.([0, 10, 20, 30, 40, 50]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16.994904 seconds (78.26 M allocations: 9.910 GiB, 25.06% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time obsval, obslon, obslat, obsdepth, obstime, obsid = loadobs(Float64, datafileobs, varname);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the observation ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Checking ranges for dimensions and observations\n",
      "└ @ DIVAnd /home/ctroupin/.julia/packages/DIVAnd/ZfEqh/src/obsstat.jl:75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              minimum and maximum of obs. dimension 1: (0.0, 359.9998474121094)\n",
      "              minimum and maximum of obs. dimension 2: (61.999000549316406, 82.94100189208984)\n",
      "              minimum and maximum of obs. dimension 3: (-0.800000011920929, 5667.0)\n",
      "              minimum and maximum of obs. dimension 4: (1931-07-06T00:00:00, 2015-02-26T13:36:00)\n",
      "                          minimum and maximum of data: (0.0, 36.959999084472656)\n"
     ]
    }
   ],
   "source": [
    "checkobs((obslon, obslat, obsdepth, obstime), obsval, obsid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longitudes go from 0° to 360°E, but we want to have them between -180° to 180°     \n",
    "(normaly than can be done with ODV during the export)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "obslon[obslon .> 180.] = obslon[obslon .> 180.] .- 360.;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality check based on range\n",
    "We see that the range for salinity is correct, so no need to check it further.     \n",
    "Modify the values and uncomment the next cell if a range checking is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sel = (obsval .<= 40) .& (obsval .>= 0);\\nobsval = obsval[sel]\\nobslon = obslon[sel]\\nobslat = obslat[sel]\\nobsdepth = obsdepth[sel]\\nobstime = obstime[sel]\\nobsid = obsid[sel];\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "sel = (obsval .<= 40) .& (obsval .>= 0);\n",
    "obsval = obsval[sel]\n",
    "obslon = obslon[sel]\n",
    "obslat = obslat[sel]\n",
    "obsdepth = obsdepth[sel]\n",
    "obstime = obstime[sel]\n",
    "obsid = obsid[sel];\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: space required before colon in \"?\" expression",
     "output_type": "error",
     "traceback": [
      "syntax: space required before colon in \"?\" expression",
      ""
     ]
    }
   ],
   "source": [
    "~(isdir(figdir)) ? mkpath(figdir): @info \"Creating directory $(figdir)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot unique observation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Total number of coordinates: 19059429\n",
      "└ @ Main In[37]:3\n",
      "┌ Info: Number of unique coordinates (profiles): 181064\n",
      "└ @ Main In[37]:4\n"
     ]
    }
   ],
   "source": [
    "coords = [(x,y) for (x,y) in zip(obslon, obslat)];\n",
    "coords_u = unique(coords);\n",
    "@info \"Total number of coordinates: $(length(coords))\"\n",
    "@info \"Number of unique coordinates (profiles): $(length(coords_u))\"\n",
    "obslon_u = [x[1] for x in coords_u];\n",
    "obslat_u = [x[2] for x in coords_u];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: obslon_u not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: obslon_u not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[12]:3"
     ]
    }
   ],
   "source": [
    "figure()\n",
    "ax = subplot(1,1,1)\n",
    "plot(obslon_u, obslat_u, \"ko\", markersize=.2)\n",
    "aspect_ratio = 1/cos(mean(latr) * pi/180)\n",
    "ax.tick_params(\"both\",labelsize=6)\n",
    "gca().set_aspect(aspect_ratio)\n",
    "savefig(joinpath(figdir, \"arctic_data_locations\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bathymetry\n",
    "We will work with a reduced resolution GEBCO bathymetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Bathymetry file already downloaded\n",
      "└ @ Main In[13]:5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.785297 seconds (9.04 M allocations: 451.481 MiB, 4.06% gc time)\n"
     ]
    }
   ],
   "source": [
    "bathname = joinpath(datadir, \"gebco_30sec_16.nc\")\n",
    "if !isfile(bathname)\n",
    "    download(\"https://dox.ulg.ac.be/index.php/s/U0pqyXhcQrXjEUX/download\", bathname)\n",
    "else\n",
    "    @info \"Bathymetry file already downloaded\"\n",
    "end\n",
    "@time bx, by, b = load_bath(bathname, true, lonr, latr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: aspect_ratio not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: aspect_ratio not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[14]:7"
     ]
    }
   ],
   "source": [
    "figure()\n",
    "ax = subplot(1,1,1)\n",
    "pcolor(bx,by,permutedims(b, [2,1]));\n",
    "cb = colorbar(orientation=\"vertical\", shrink=0.65)\n",
    "cb.ax.tick_params(labelsize=8)\n",
    "contour(bx,by,permutedims(b, [2,1]), [0, 0.1], colors=\"k\", linewidths=.5)\n",
    "gca().set_aspect(aspect_ratio)\n",
    "ax.tick_params(\"both\",labelsize=6)\n",
    "savefig(joinpath(figdir, \"arctic_bathymetry\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Land-sea mask\n",
    "We start with the surface mask to have a first idea of how the mask looks like.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfwater = b .>= depthr[1]\n",
    "label = DIVAnd.floodfill(surfwater)\n",
    "surfmask = label .== 1; # largest area has the label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: aspect_ratio not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: aspect_ratio not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[16]:2"
     ]
    }
   ],
   "source": [
    "figure()\n",
    "gca().set_aspect(aspect_ratio)\n",
    "gca().tick_params(\"both\", labelsize=6)\n",
    "pcolor(bx, by ,surfmask', cmap=PyPlot.cm.binary_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(mask) = (201, 131, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(201, 131, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = falses(size(b,1),size(b,2),length(depthr))\n",
    "for k = 1:length(depthr)\n",
    "    for j = 1:size(b,2)\n",
    "        for i = 1:size(b,1)\n",
    "            mask[i,j,k] = (b[i,j] >= depthr[k]) && surfmask[i,j]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "@show size(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### Background\n",
    "The background field is a 10-year reference field prior to the analysis year    \n",
    "For example for analysis year 2018, the period for the background is 2008-2017.     \n",
    "The variable `yearlist` is then defined as a list of ranges (change the values in the [ ] to have the start and the end year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Array{UnitRange{Int64},1}:\n",
       " 2000:2009\n",
       " 2001:2010\n",
       " 2002:2011\n",
       " 2003:2012\n",
       " 2004:2013\n",
       " 2005:2014\n",
       " 2006:2015\n",
       " 2007:2016\n",
       " 2008:2017"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearlist = [y-10:y-1 for y = 2010:2018];\n",
    "yearlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlist = [[2,3,4], [5,6,7], [8,9,10], [11,12,1]];  # Seasonal climatology\n",
    "TSbackground = DIVAnd.TimeSelectorYearListMonthList(yearlist,monthlist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Water_body_salinity_Arctic.4Danl.nc\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = (length(lonr), length(latr), length(depthr));\n",
    "lenx = fill(200_000.,sz)   # 200 km\n",
    "leny = fill(200_000.,sz)   # 200 km\n",
    "lenz = [min(max(30.,depthr[k]/150),300.) for i = 1:sz[1], j = 1:sz[2], k = 1:sz[3]]\n",
    "len = (lenx, leny, lenz);\n",
    "epsilon2 = 0.1;\n",
    "\n",
    "filenamebackground = \"Water_body_$(replace(varname,\" \"=>\"_\"))_Arctic_background.4Danl.nc\"\n",
    "filename = \"Water_body_$(replace(varname,\" \"=>\"_\"))_Arctic.4Danl.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata for the netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = OrderedDict(\n",
    "    # Name of the project (SeaDataCloud, SeaDataNet, EMODNET-chemistry, ...)\n",
    "    \"project\" => \"SeaDataCloud\",\n",
    "\n",
    "    # URN code for the institution EDMO registry,\n",
    "    # e.g. SDN:EDMO::1579\n",
    "    \"institution_urn\" => \"SDN:EDMO::1579\",\n",
    "\n",
    "    # Production group\n",
    "    #\"production\" => \"Diva group\",\n",
    "\n",
    "    # Name and emails from authors\n",
    "    \"Author_e-mail\" => [\"Your Name1 <name1@example.com>\", \"Other Name <name2@example.com>\"],\n",
    "\n",
    "    # Source of the observation\n",
    "    \"source\" => \"observational data from SeaDataNet and World Ocean Atlas\",\n",
    "\n",
    "    # Additional comment\n",
    "    \"comment\" => \"Duplicate removal applied to the merged dataset\",\n",
    "\n",
    "    # SeaDataNet Vocabulary P35 URN\n",
    "    # http://seadatanet.maris2.nl/v_bodc_vocab_v2/search.asp?lib=p35\n",
    "    # example: SDN:P35::WATERTEMP\n",
    "    \"parameter_keyword_urn\" => \"SDN:P35::EPC00001\",\n",
    "\n",
    "    # List of SeaDataNet Parameter Discovery Vocabulary P02 URNs\n",
    "    # http://seadatanet.maris2.nl/v_bodc_vocab_v2/search.asp?lib=p02\n",
    "    # example: [\"SDN:P02::TEMP\"]\n",
    "    \"search_keywords_urn\" => [\"SDN:P02::PSAL\"],\n",
    "\n",
    "    # List of SeaDataNet Vocabulary C19 area URNs\n",
    "    # SeaVoX salt and fresh water body gazetteer (C19)\n",
    "    # http://seadatanet.maris2.nl/v_bodc_vocab_v2/search.asp?lib=C19\n",
    "    # example: [\"SDN:C19::3_1\"]\n",
    "    \"area_keywords_urn\" => [\"SDN:C19::3_3\"],\n",
    "\n",
    "    \"product_version\" => \"1.0\",\n",
    "    \n",
    "    \"product_code\" => \"something-to-decide\",\n",
    "    \n",
    "    # bathymetry source acknowledgement\n",
    "    # see, e.g.\n",
    "    # * EMODnet Bathymetry Consortium (2016): EMODnet Digital Bathymetry (DTM).\n",
    "    # https://doi.org/10.12770/c7b53704-999d-4721-b1a3-04ec60c87238\n",
    "    # \n",
    "    # taken from\n",
    "    # http://www.emodnet-bathymetry.eu/data-products/acknowledgement-in-publications\n",
    "    #\n",
    "    # * The GEBCO Digital Atlas published by the British Oceanographic Data Centre on behalf of IOC and IHO, 2003\n",
    "    #\n",
    "    # taken from\n",
    "    # https://www.bodc.ac.uk/projects/data_management/international/gebco/gebco_digital_atlas/copyright_and_attribution/\n",
    "        \n",
    "    \"bathymetry_source\" => \"The GEBCO Digital Atlas published by the British Oceanographic Data Centre on behalf of IOC and IHO, 2003\",\n",
    "\n",
    "    # NetCDF CF standard name\n",
    "    # http://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html\n",
    "    # example \"standard_name\" = \"sea_water_temperature\",\n",
    "    \"netcdf_standard_name\" => \"sea_water_salinity\",\n",
    "\n",
    "    \"netcdf_long_name\" => \"sea water salinity\",\n",
    "\n",
    "    \"netcdf_units\" => \"1e-3\",\n",
    "\n",
    "    # Abstract for the product\n",
    "    \"abstract\" => \"...\",\n",
    "\n",
    "    # This option provides a place to acknowledge various types of support for the\n",
    "    # project that produced the data\n",
    "    \"acknowledgement\" => \"...\",\n",
    "\n",
    "    \"documentation\" => \"https://doi.org/doi_of_doc\",\n",
    "\n",
    "    # Digital Object Identifier of the data product\n",
    "    \"doi\" => \"...\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the metadata  before running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict(\"project\" => \"SeaDataCloud\",\"institution\" => \"University of Liege, GeoHydrodynamics and Environment Research\",\"institution_urn\" => \"SDN:EDMO::1579\",\"Author_e-mail\" => \"Your Name1 <name1@example.com>, Other Name <name2@example.com>\",\"source\" => \"observational data from SeaDataNet and World Ocean Atlas\",\"comment\" => \"Duplicate removal applied to the merged dataset\",\"parameter_keyword\" => \"Water body salinity\",\"parameter_keyword_urn\" => \"SDN:P35::EPC00001\",\"search_keywords\" => \"Salinity of the water column\",\"search_keywords_urn\" => \"SDN:P02::PSAL\"…), OrderedDict(\"units\" => \"1e-3\",\"standard_name\" => \"sea_water_salinity\",\"long_name\" => \"sea water salinity\"))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncglobalattrib, ncvarattrib = SDNMetadata(metadata, filename, varname, lonr, latr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the background file if it already exists, and create the figure directory if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Removing file Water_body_salinity_Arctic_background.4Danl.nc\n",
      "└ @ Main In[23]:3\n"
     ]
    }
   ],
   "source": [
    "if isfile(filenamebackground)\n",
    "    rm(filenamebackground) # delete the previous analysis\n",
    "    @info \"Removing file $filenamebackground\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a plotting function that well be applied at each time and depth level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plotres (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plotres(timeindex, sel, fit, erri)\n",
    "    tmp = copy(fit)\n",
    "    nx,ny,nz = size(tmp)\n",
    "    for i in 1:nz\n",
    "        figure(\"Arctic analysis\")\n",
    "        ax = subplot(1,1,1)\n",
    "        ax.tick_params(\"both\",labelsize=6)\n",
    "        ylim(minimum(latr) - Δy, maximum(latr) + Δy);\n",
    "        xlim(minimum(lonr) - Δx, maximum(lonr) + Δx);\n",
    "        title(\"Depth: $(depthr[i]) \\n Time index: $(timeindex)\", fontsize=6)\n",
    "        pcolor(lonr.-Δx/2.,latr.-Δy/2, permutedims(tmp[:,:,i], [2,1]);\n",
    "               vmin = 30., vmax = 38.)\n",
    "        cb = colorbar(extend=\"max\", orientation=\"vertical\", shrink=0.8)\n",
    "        cb.ax.tick_params(labelsize=8)\n",
    "\n",
    "        contourf(bx,by,permutedims(b,[2,1]), levels = [-1e5,0], colors = [[.5,.5,.5]])\n",
    "        gca().set_aspect(aspect_ratio)\n",
    "\n",
    "        figname = varname * @sprintf(\"_%02d\",i) * @sprintf(\"_%03d_background.png\",timeindex) \n",
    "        @info(figname)\n",
    "        PyPlot.savefig(joinpath(figdir, figname), dpi=300, bbox_inches=\"tight\");\n",
    "        PyPlot.close_figs()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background analysis\n",
    "We now have all the input to prepare the background field with `diva3d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: obslon not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: obslon not defined",
      "",
      "Stacktrace:",
      " [1] macro expansion at ./util.jl:175 [inlined]",
      " [2] top-level scope at ./In[25]:1"
     ]
    }
   ],
   "source": [
    "dbinfo = @time diva3d((lonr,latr,depthr,TSbackground),\n",
    "           (obslon,obslat,obsdepth,obstime), obsval,\n",
    "           len, epsilon2,\n",
    "           filenamebackground,varname,\n",
    "           bathname=bathname,\n",
    "           mask = mask,\n",
    "           plotres=plotres,\n",
    "           fitcorrlen = false,\n",
    "           niter_e = 2,\n",
    "           solver = :direct,\n",
    "           MEMTOFIT = 120,\n",
    "       );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final analysis\n",
    "#### Parameters\n",
    "We define the periods of interest for the final climatology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearlist = [[2010:2018]];\n",
    "monthlist = [[1,2,3],[4,5,6],[7,8,9],[10,11,12]];  # Seasonal climatology\n",
    "TS = DIVAnd.TimeSelectorYearListMonthList(yearlist,monthlist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the final netCDF file if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(filename)\n",
    "    rm(filename) # delete the previous analysis\n",
    "    @info \"Removing file $filename\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the analysis using background field, defined through the option      \n",
    "`background = DIVAnd.backgroundfile(filenamebackground,varname,TSbackground)`:      \n",
    "* `filenamebackground` is the name of the netCDF that you have created with the background\n",
    "* `varname` is the name of the variable as written in the background netCDF and\n",
    "* `TSbackground` is the *TimeSelector` object used to compute the background.\n",
    "\n",
    "With these options set, the new analysis will select the correct background according to the considered period.     \n",
    "We now have 16 time steps: 4 seasons times 4 year periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NCDatasets.NetCDFError",
     "evalue": "NetCDF error: Opening path Water_body_salinity_Arctic_background.4Danl.nc: No such file or directory (NetCDF error code: 2)",
     "output_type": "error",
     "traceback": [
      "NetCDF error: Opening path Water_body_salinity_Arctic_background.4Danl.nc: No such file or directory (NetCDF error code: 2)",
      "",
      "Stacktrace:",
      " [1] nc_open(::String, ::UInt16) at /home/ctroupin/.julia/packages/NCDatasets/Tb4eK/src/netcdf_c.jl:281",
      " [2] NCDataset(::String, ::String; format::Symbol, diskless::Bool, persist::Bool, attrib::Array{Any,1}) at /home/ctroupin/.julia/packages/NCDatasets/Tb4eK/src/dataset.jl:213",
      " [3] NCDataset at /home/ctroupin/.julia/packages/NCDatasets/Tb4eK/src/dataset.jl:198 [inlined] (repeats 2 times)",
      " [4] backgroundfile(::String, ::String, ::TimeSelectorYearListMonthList{Array{UnitRange{Int64},1},Array{Array{Int64,1},1}}) at /home/ctroupin/.julia/packages/DIVAnd/ZfEqh/src/utils.jl:732",
      " [5] macro expansion at ./util.jl:175 [inlined]",
      " [6] top-level scope at ./In[28]:1"
     ]
    }
   ],
   "source": [
    "dbinfo = @time diva3d((lonr,latr,depthr,TS),\n",
    "    (obslon,obslat,obsdepth,obstime), obsval,\n",
    "    len, epsilon2,\n",
    "    filename,varname,\n",
    "    bathname=bathname,\n",
    "    plotres = plotres,\n",
    "    mask = mask,\n",
    "    fitcorrlen = false,\n",
    "    niter_e = 2,\n",
    "    background = DIVAnd.backgroundfile(filenamebackground,varname,TSbackground),\n",
    "    solver = solver,\n",
    "    MEMTOFIT = 120,\n",
    ");\n",
    "\n",
    "@show length(obslat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isfile(filenamebackground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
